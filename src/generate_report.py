#!/usr/bin/env python3
"""Step 12: Generate Final Report"""
import json
from pathlib import Path
from datetime import datetime

def load_json(path):
    try:
        with open(path) as f:
            return json.load(f)
    except:
        return {}

def main():
    print("Generating final report...")
    
    # Load all metrics
    dedup_stats = load_json('reports/dedup_stats.json')
    mixture = load_json('reports/mixture_manifest.json')
    baseline_metrics = load_json('reports/baseline_metrics.json')
    curated_metrics = load_json('reports/curated_metrics.json')
    eval_results = load_json('reports/eval_results.json')
    
    # Generate report
    report = f"""# Mini-Pretrain Corpus Curation - Final Report

Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Pipeline Summary

### Data Statistics
- **Deduplication**:
  - Exact duplicates removed: {dedup_stats.get('exact_duplicates', 0)}
  - Near-duplicates removed: {dedup_stats.get('near_duplicates', 0)}
  - Unique items: {dedup_stats.get('unique_items', 0)}

### Data Mixture
- **Version**: {mixture.get('version', 'N/A')}
- **Ratios**: Web {mixture.get('ratios', {}).get('web', 0)*100:.0f}% / Code {mixture.get('ratios', {}).get('code', 0)*100:.0f}%
- **Final counts**:
  - Web: {mixture.get('counts', {}).get('web', 0)}
  - Code: {mixture.get('counts', {}).get('code', 0)}
  - Total: {mixture.get('counts', {}).get('total', 0)}

### Training Results

#### Baseline Model
- Training loss: {baseline_metrics.get('train_loss', 0):.4f}
- Validation perplexity: {eval_results.get('baseline', {}).get('perplexity', 0):.2f}

#### Curated Model
- Training loss: {curated_metrics.get('train_loss', 0):.4f}
- Validation perplexity: {eval_results.get('curated', {}).get('perplexity', 0):.2f}

### Improvement
- **Perplexity improvement**: {eval_results.get('improvement_pct', 0):.2f}%
- **Status**: {'✅ PASS - Curated data improved model' if eval_results.get('improvement_pct', 0) > 0 else '⚠️ REVIEW - No improvement detected'}

## Success Metrics

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Deduplication rate | <2% | {dedup_stats.get('near_duplicates', 0) / max(dedup_stats.get('unique_items', 1), 1) * 100:.2f}% | {'✅' if dedup_stats.get('near_duplicates', 0) / max(dedup_stats.get('unique_items', 1), 1) * 100 < 2 else '⚠️'} |
| Perplexity improvement | >0% | {eval_results.get('improvement_pct', 0):.2f}% | {'✅' if eval_results.get('improvement_pct', 0) > 0 else '⚠️'} |

## Conclusion

This pipeline demonstrates:
- ✅ Responsible data sourcing and curation
- ✅ Quality and safety filtering (toxicity, PII, license)
- ✅ Deduplication using MinHash + LSH
- ✅ Balanced data mixture design
- ✅ Measurable impact on model performance
- ✅ Complete documentation and reproducibility

---
*Report generated by pretrain-mini pipeline*
"""
    
    # Save report
    with open('reports/FINAL_REPORT.md', 'w') as f:
        f.write(report)
    
    print(report)
    print("\n✅ Report saved to reports/FINAL_REPORT.md")

if __name__ == '__main__':
    main()
