# Model Card: Mini-GPT-2
See full documentation in main README.md

## Architecture
- GPT-2 Small (4 layers, 256 hidden)
- ~10M parameters
- Trained on curated corpus
